# Self-Supervised Learning


利用 **数据本身可观测的结构**(空间、时间、视图同源性) 自动生成训练信号，形成 **伪监督**

自监督学习 (SSL) 得到的 backbone = 高质量特征提取器

后续工作
1. 部分任务 无标签 / 极少标签就能直接上手，eg : 检索、聚类、异常检测、最近邻分类、Zero-shot 等
2. 其他需要 少量标签微调，需要输出 明确 类别、坐标、分割掩码 时，仍需监督信号，但所需标注量通常是从头训练的 10% 甚至 1%


对比式 (Contrastive)
1. 方法简介
   1. 同一张样本 经两次随机增广 形成 正样本对 (positive)
   2. 其它样本 视作 负样本 (negative)
2. Loss : InfoNCE / NT-Xent
3. 目的 : 同源视图拉近，异源拉远 ⇒ 学到判别式表征


遮盖-重建 (Masked/Denoising)
1. 方法简介
   1. 随机遮盖 token 或 patch
   2. 剩余部分 - 输入
   3. 遮盖部分 - 预测目标
2. Loss : 交叉熵 / MSE
3. 目的 : 迫使模型理解上下文或图像结构，具备生成式能力


时序预测 (Future Frame)
1. 方法简介
   1. 输入前 n 帧，要预测第 n+k 帧，或预测未来潜码
2. Loss : 交叉熵 / 对比损失






JEPA-based
1. I-JEPA
2. V-JEPA
