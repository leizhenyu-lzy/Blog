CLIP (Contrastive Language Image Pre-Training)
1. 用于多模态学习的模型(将图像和文本对齐)
2. 通过对大量的 图像-文本对(image-text pairs) 进行对比学习，将 图像 & 描述文本 嵌入到同一个向量空间
3. 架构
   1. 视觉编码器 (Vision Encoder)
   2. 文本编码器 (Text Encoder)
4. 具有 Zero-Shot 能力